@inproceedings{rocha2023epia,
 abstract = {The recent success of Large Language Models (LLMs) has sparked concerns about their potential to spread misinformation. As a result, there is a pressing need for tools to identify ``fake arguments'' generated by such models. To create these tools, examples of texts generated by LLMs are needed. This paper introduces a methodology to obtain good, bad and ugly arguments from argumentative essays produced by ChatGPT, OpenAI's LLM. We then describe a novel dataset containing a set of diverse arguments, ArGPT. We assess the effectiveness of our dataset and establish baselines for several argumentation-related tasks. Finally, we show that the artificially generated data relates well to human argumentation and thus is useful as a tool to train and test systems for the defined tasks.},
 address = {Cham},
 author = {Rocha, Victor Hugo Nascimento
and Silveira, Igor Cataneo
and Pirozelli, Paulo
and Mauá, Denis Deratani
and Cozman, Fabio Gagliardi},
 booktitle = {Progress in Artificial Intelligence},
 editor = {Moniz, Nuno
and Vale, Zita
and Cascalho, José
and Silva, Catarina
and Sebastião, Raquel},
 isbn = {978-3-031-49008-8},
 doi = {10.1007/978-3-031-49008-8_34},
 pages = {428--440},
 publisher = {Springer Nature Switzerland},
 title = {Assessing Good, Bad and Ugly Arguments Generated by ChatGPT: a New Dataset, its Methodology and Associated Tasks},
 year = {2023}
}
