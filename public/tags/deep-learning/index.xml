<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | </title>
    <link>http://localhost:1313/~ddm/tags/deep-learning/</link>
      <atom:link href="http://localhost:1313/~ddm/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Feb 2023 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/~ddm/media/icon_hu_645fa481986063ef.png</url>
      <title>Deep Learning</title>
      <link>http://localhost:1313/~ddm/tags/deep-learning/</link>
    </image>
    
    <item>
      <title>Neural Inductive Logic Programming</title>
      <link>http://localhost:1313/~ddm/project/neuroproblog/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/~ddm/project/neuroproblog/</guid>
      <description>&lt;h2 id=&#34;hahahugoshortcode17s0hbhb-funding&#34;&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M2.25 18.75a60.07 60.07 0 0 1 15.797 2.101c.727.198 1.453-.342 1.453-1.096V18.75M3.75 4.5v.75A.75.75 0 0 1 3 6h-.75m0 0v-.375c0-.621.504-1.125 1.125-1.125H20.25M2.25 6v9m18-10.5v.75c0 .414.336.75.75.75h.75m-1.5-1.5h.375c.621 0 1.125.504 1.125 1.125v9.75c0 .621-.504 1.125-1.125 1.125h-.375m1.5-1.5H21a.75.75 0 0 0-.75.75v.75m0 0H3.75m0 0h-.375a1.125 1.125 0 0 1-1.125-1.125V15m1.5 1.5v-.75A.75.75 0 0 0 3 15h-.75M15 10.5a3 3 0 1 1-6 0a3 3 0 0 1 6 0m3 0h.008v.008H18zm-12 0h.008v.008H6z&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Funding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;FAPESP PI 2022/02937-9 (2023-02-01 to 2028-01-31)&lt;/li&gt;
&lt;li&gt;CNPq Productivity 305136/2022-4 (2023-03-01 to 2026-02-28)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hahahugoshortcode17s1hbhb-participants&#34;&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M15 19.128a9.38 9.38 0 0 0 2.625.372a9.337 9.337 0 0 0 4.121-.952a4.125 4.125 0 0 0-7.533-2.493M15 19.128v-.003c0-1.113-.285-2.16-.786-3.07M15 19.128v.106A12.318 12.318 0 0 1 8.624 21c-2.331 0-4.512-.645-6.374-1.766l-.001-.109a6.375 6.375 0 0 1 11.964-3.07M12 6.375a3.375 3.375 0 1 1-6.75 0a3.375 3.375 0 0 1 6.75 0m8.25 2.25a2.625 2.625 0 1 1-5.25 0a2.625 2.625 0 0 1 5.25 0&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; Participants&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Denis Deratani Mauá, Coordinator&lt;/li&gt;
&lt;li&gt;Fabio G. Cozman, Associated Researcher&lt;/li&gt;
&lt;li&gt;Igor Cataneo Silveira, PhD candidate, Researcher&lt;/li&gt;
&lt;li&gt;Naomi de Moraes, PhD candidate, Researcher&lt;/li&gt;
&lt;li&gt;Renato Lui Geh, Software Developer, Researcher&lt;/li&gt;
&lt;li&gt;Jonas Gonçalves, MSc student, Researcher&lt;/li&gt;
&lt;li&gt;Thiago Casagrande, MSc student, Researcher&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Deep learning techniques have shown impressive results in low-level cognitive task such as image and speech recognition as well as in high-level cognitive tasks such as question answering and stochastic planning. Yet, developing effective deep learning solutions is notoriously challenging as they require massive amounts of data and compute (often beyond limited budgets of typical users), are very sensitive to domain shifts, and produce undesirable output that undermine end-user trust in the system. Good old-fashioned AI techniques based on knowledge representation and symbol manipulation are data efficient, generalizable, and produce mostly verifiable behavior; however they scale poorly, require costly knowledge acquisition procedures and have difficulty in coping with noise and uncertainty that are ubiquitous in real settings. Neurosymbolic approaches have recently re-emerged as a means to take the best of both approaches and deliver systems that are expressive and scalable, yet interpretable, generalizable, data efficient and trustworthy. This document describes a five-year research proposal to study the further development of neurosymbolic approaches based on logic programming, procedural probabilistic programming and combinations of both. Ultimately, this research seeks to advance the state-of-the-art of learning-based agents that go beyond the dominant view of learning as an optimization task in a continuous space guided by input-output examples. To this end, we shall extend current neursymbolic logic programming systems with more expressive constructs and more efficient learning techniques, and evaluate them in challenging cognitive tasks such as text-based question answering and argumentation.&lt;/p&gt;
&lt;h2 id=&#34;outcomes&#34;&gt;Outcomes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M12 21a9.004 9.004 0 0 0 8.716-6.747M12 21a9.004 9.004 0 0 1-8.716-6.747M12 21c2.485 0 4.5-4.03 4.5-9S14.485 3 12 3m0 18c-2.485 0-4.5-4.03-4.5-9S9.515 3 12 3m0 0a8.997 8.997 0 0 1 7.843 4.582M12 3a8.997 8.997 0 0 0-7.843 4.582m15.686 0A11.953 11.953 0 0 1 12 10.5c-2.998 0-5.74-1.1-7.843-2.918m15.686 0A8.959 8.959 0 0 1 21 12c0 .778-.099 1.533-.284 2.253m0 0A17.919 17.919 0 0 1 12 16.5a17.92 17.92 0 0 1-8.716-2.247m0 0A9.015 9.015 0 0 1 3 12c0-1.605.42-3.113 1.157-4.418&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; The dPASP system: 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tutorial: 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; 
&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;
  &lt;span class=&#34;inline-block  pr-1&#34;&gt;
    &lt;svg style=&#34;height: 1em; transform: translateY(0.1em);&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34; viewBox=&#34;0 0 24 24&#34;&gt;&lt;path fill=&#34;none&#34; stroke=&#34;currentColor&#34; stroke-linecap=&#34;round&#34; stroke-linejoin=&#34;round&#34; stroke-width=&#34;1.5&#34; d=&#34;M19.5 14.25v-2.625a3.375 3.375 0 0 0-3.375-3.375h-1.5A1.125 1.125 0 0 1 13.5 7.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H8.25m0 12.75h7.5m-7.5 3H12M10.5 2.25H5.625c-.621 0-1.125.504-1.125 1.125v17.25c0 .621.504 1.125 1.125 1.125h12.75c.621 0 1.125-.504 1.125-1.125V11.25a9 9 0 0 0-9-9&#34;/&gt;&lt;/svg&gt;
  &lt;/span&gt; 
&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
